{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8co7NCriW33DNQx8vECZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawn-kg/DataMining/blob/main/assign7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN"
      ],
      "metadata": {
        "id": "RAobkpRN4RvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Processing"
      ],
      "metadata": {
        "id": "jznPGvG6cJwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DWSwp5t4Lc9",
        "outputId": "6802ce0e-a3d0-4cb5-d4ab-ca5ed7b36f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6599\n",
            "2199\n",
            "263256\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "f = open(\"./Train_Arabic_Digit.txt\")\n",
        "f.readline()\n",
        "\n",
        "Train_Data = dict()\n",
        "\n",
        "m = []\n",
        "count = 0\n",
        "count2 = 0\n",
        "for line in f:\n",
        "  if (line.isspace()):\n",
        "    Train_Data[count] = np.array(m.copy())\n",
        "    count+=1\n",
        "    m = []\n",
        "    continue\n",
        "  count2+=1\n",
        "  m.append([float(num) for num in line.split()])\n",
        "f.close()\n",
        "\n",
        "f2 = open(\"./Test_Arabic_Digit.txt\")\n",
        "f2.readline()\n",
        "Test_Data = dict()\n",
        "m2 = []\n",
        "count = 0\n",
        "for line in f2:\n",
        "  if (line.isspace()):\n",
        "    Test_Data[count] = np.array(m2.copy())\n",
        "    count+=1\n",
        "    m2 = []\n",
        "    continue\n",
        "  m2.append([float(num) for num in line.split()])\n",
        "f2.close()\n",
        "\n",
        "print(len(Train_Data))\n",
        "print(len(Test_Data))\n",
        "print(count2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = np.zeros((10,10))\n",
        "for m in range(10):\n",
        "  target[m][m] = 1\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T5ozI9OL5Ku",
        "outputId": "6a97e18b-1b73-4d13-aad0-d28e8538bf29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN Algorithm"
      ],
      "metadata": {
        "id": "zjQQR6g3cRVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.special\n",
        "np.random.seed(42)\n",
        "numneur = 32\n",
        "b_h = np.random.random_sample((numneur,1))\n",
        "b_o = np.random.random_sample((10,1))\n",
        "W_i = np.random.random_sample((13,numneur))\n",
        "W_h = np.random.random_sample((numneur,numneur))\n",
        "W_o = np.random.random_sample((numneur,10))\n",
        "\n",
        "order = np.array(range(len(Train_Data)))\n",
        "\n",
        "error = 0\n",
        "\n",
        "for z in range(20):\n",
        "  np.random.shuffle(order)\n",
        "  acc_count = 0\n",
        "  error = 0\n",
        "  for i in order:\n",
        "    tau = len(Train_Data[i]);\n",
        "    h = np.zeros((tau+1,numneur))\n",
        "\n",
        "\n",
        "    # forward propagation\n",
        "    h_0 = np.zeros((numneur))\n",
        "    h[0] = h_0\n",
        "    for t in range(1,tau):\n",
        "      h_prev = h[t-1].reshape(-1,1)\n",
        "      netzj = np.dot(W_i.transpose(),Train_Data[i][t].reshape(-1,1)) + np.dot(W_h.transpose(),h_prev) + b_h\n",
        "      h_t = np.zeros((numneur,1))\n",
        "      # relu\n",
        "      for j in range(numneur):\n",
        "        if (netzj[j]<=0):\n",
        "          h_t[j] = 0\n",
        "        else:\n",
        "          h_t[j] = netzj[j]\n",
        "      h[t] = h_t.reshape(1,-1)\n",
        "    netoi = np.dot(W_o.transpose(),h[-1].reshape(-1,1)) + b_o\n",
        "    Oi = scipy.special.softmax(netoi)\n",
        "\n",
        "    ind = i // 660\n",
        "    pred_ind = np.argmax(Oi)\n",
        "    if ind==pred_ind:\n",
        "      acc_count+=1\n",
        "    CE = 0\n",
        "    for l in range(10):\n",
        "      CE += target[ind][l]*np.log(Oi[l])\n",
        "    CE = -CE\n",
        "    error+=CE\n",
        "\n",
        "\n",
        "    # back propagation\n",
        "    So = Oi - target[ind].reshape(-1,1)\n",
        "    reluDer = np.zeros((numneur))\n",
        "    for d in range(numneur):\n",
        "      if h[-1][d]<=0:\n",
        "        reluDer[d] = 0\n",
        "      else:\n",
        "        reluDer[d] = 1\n",
        "    temp = W_o@So\n",
        "    reluDer = reluDer.reshape(-1,1)\n",
        "    Sh = np.multiply(reluDer, temp)\n",
        "    S = np.zeros((tau,numneur))\n",
        "    S[-1] = Sh.reshape(1,-1)\n",
        "    for t in reversed(range(tau-1)):\n",
        "      reluDeritr = np.zeros((numneur))\n",
        "      for d in range(numneur):\n",
        "        if h[t][d]<=0:\n",
        "          reluDeritr[d] = 0\n",
        "        else:\n",
        "          reluDeritr[d] = 1\n",
        "      tempitr = W_h@S[t+1]\n",
        "      reluDeritr = reluDeritr.reshape(-1,1)\n",
        "      Sh_tr = np.multiply(reluDeritr, tempitr.reshape(-1,1))\n",
        "      S[t] = Sh_tr.reshape(1,-1)\n",
        "    gradb_o = So\n",
        "    gradw_o = np.dot(h[-1].reshape(-1,1),So.transpose())\n",
        "    gradb_h = 0\n",
        "    for t in range(tau):\n",
        "      gradb_h+=S[t]\n",
        "    gradw_h = np.zeros(W_h.shape)\n",
        "    for m in range(1,tau):\n",
        "      gradw_h+=h[m-1]@S[m].transpose()\n",
        "    gradw_i = 0\n",
        "    for t in range(tau):\n",
        "      gradw_i += np.dot(Train_Data[i][t].reshape(-1,1),S[t].reshape(-1,1).transpose())\n",
        "    b_o = b_o - .001*gradb_o\n",
        "    W_o = W_o - .001*gradw_o\n",
        "    b_h = b_h - .001*gradb_h.reshape(-1,1)\n",
        "    W_h = W_h - .001*gradw_h\n",
        "    W_i = W_i - .001*gradw_i\n",
        "  # print(\"Output Bias and Weight gradients\")\n",
        "  # print(gradb_o)\n",
        "  # print(gradw_o)\n",
        "  # print(\"Hidden Bias and Weight gradients\")\n",
        "  # print(gradb_h)\n",
        "  # print(gradw_h)\n",
        "  # print(\"Input Weight gradient\")\n",
        "  # print(gradw_i)\n",
        "  print(acc_count/6559)\n",
        "  print(error/6559)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xos_YbE0I-CX",
        "outputId": "d238eb8d-964f-40ac-95e4-e3cd0acd5408"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09727092544595213\n",
            "[2.34711684]\n",
            "0.0997103216953804\n",
            "[2.32502387]\n",
            "0.0974233877115414\n",
            "[2.31912468]\n",
            "0.09193474615032779\n",
            "[2.31763389]\n",
            "0.09864308583625553\n",
            "[2.31719238]\n",
            "0.09483152919652386\n",
            "[2.31708692]\n",
            "0.09345936880622047\n",
            "[2.31705817]\n",
            "0.09528891599329166\n",
            "[2.31705965]\n",
            "0.08964781216648879\n",
            "[2.31703378]\n",
            "0.09391675560298826\n",
            "[2.31704116]\n",
            "0.09650861411800579\n",
            "[2.3170267]\n",
            "0.09544137825888092\n",
            "[2.31704512]\n",
            "0.0901051989632566\n",
            "[2.31703759]\n",
            "0.09345936880622047\n",
            "[2.31701569]\n",
            "0.09696600091477359\n",
            "[2.31703814]\n",
            "0.09681353864918432\n",
            "[2.31703375]\n",
            "0.09422168013416679\n",
            "[2.31704296]\n",
            "0.09437414239975606\n",
            "[2.31699597]\n",
            "0.09483152919652386\n",
            "[2.31702717]\n",
            "0.09361183107180973\n",
            "[2.31704203]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I could not get my accuracy over 10%."
      ],
      "metadata": {
        "id": "ZNRcwKdVmPS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for i in order:\n",
        "  tau = len(Train_Data[i]);\n",
        "  h = np.zeros((tau+1,numneur))\n",
        "\n",
        "\n",
        "  # forward propagation\n",
        "  h_0 = np.zeros((numneur))\n",
        "  h[0] = h_0\n",
        "  for t in range(1,tau):\n",
        "    h_prev = h[t-1].reshape(-1,1)\n",
        "    netzj = np.dot(W_i.transpose(),Train_Data[i][t].reshape(-1,1)) + np.dot(W_h.transpose(),h_prev) + b_h\n",
        "    h_t = np.zeros((numneur,1))\n",
        "    # relu\n",
        "    for j in range(numneur):\n",
        "      if (netzj[j]<=0):\n",
        "        h_t[j] = 0\n",
        "      else:\n",
        "        h_t[j] = netzj[j]\n",
        "    h[t] = h_t.reshape(1,-1)\n",
        "  netoi = np.dot(W_o.transpose(),h[-1].reshape(-1,1)) + b_o\n",
        "  Oi = scipy.special.softmax(netoi)\n",
        "  \n",
        "  CE = 0\n",
        "  for l in range(10):\n",
        "    CE += target[ind][l]*np.log(Oi[l])\n",
        "  CE = -CE\n",
        "  error+=CE\n",
        "  ind = i // 660\n",
        "  pred_ind = np.argmax(Oi)\n",
        "  if ind==pred_ind:\n",
        "    count+=1\n",
        "print(\"Accuracy\")\n",
        "print(count/6559)\n",
        "print(\"Cross Entropy Loss\")\n",
        "print(error/6559)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTVZGU363ewh",
        "outputId": "2b682f15-0941-4c0f-f0e1-dac62e034e5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy\n",
            "0.100625095288916\n",
            "Cross Entropy Loss\n",
            "[8.49403276]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for z in Test_Data.keys():\n",
        "  tau = len(Test_Data[z]);\n",
        "  h = np.zeros((tau+1,numneur))\n",
        "\n",
        "\n",
        "  # forward propagation\n",
        "  h_0 = np.zeros((numneur))\n",
        "  h[0] = h_0\n",
        "  for t in range(1,tau):\n",
        "    h_prev = h[t-1].reshape(-1,1)\n",
        "    netzj = np.dot(W_i.transpose(),Test_Data[z][t].reshape(-1,1)) + np.dot(W_h.transpose(),h_prev) + b_h\n",
        "    h_t = np.zeros((numneur,1))\n",
        "    # relu\n",
        "    for j in range(numneur):\n",
        "      if (netzj[j]<=0):\n",
        "        h_t[j] = 0\n",
        "      else:\n",
        "        h_t[j] = netzj[j]\n",
        "    h[t] = h_t.reshape(1,-1)\n",
        "  netoi = np.dot(W_o.transpose(),h[-1].reshape(-1,1)) + b_o\n",
        "  Oi = scipy.special.softmax(netoi)\n",
        "  CE = 0\n",
        "  for l in range(10):\n",
        "    CE += target[ind][l]*np.log(Oi[l])\n",
        "  CE = -CE\n",
        "  error+=CE\n",
        "\n",
        "  ind = z // 220\n",
        "  pred_ind = np.argmax(Oi)\n",
        "  if ind==pred_ind:\n",
        "    count+=1\n",
        "print(\"Accuracy\")\n",
        "print(count/2199)\n",
        "print(\"Cross Entropy Loss\")\n",
        "print(error/2199)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnPC-0Rb5Z77",
        "outputId": "3b56c308-d53e-49b0-a320-cb13d0e2b676"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy\n",
            "0.10004547521600728\n",
            "Cross Entropy Loss\n",
            "[27.63790337]\n"
          ]
        }
      ]
    }
  ]
}