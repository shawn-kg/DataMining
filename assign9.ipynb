{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtWr665TRYQivj8/7U/5S+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawn-kg/DataMining/blob/main/assign9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "iZBlCbeZ3nwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Npap8JW3gOD",
        "outputId": "5b1d643b-1c56-43d4-fb40-65122500ca6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.13106819 0.18467134 0.05434706 ... 0.         0.03486529 0.01493388]\n",
            " [0.10635327 0.36072198 0.08601998 ... 0.02367257 0.02852615 0.00809394]\n",
            " [0.14558995 0.16150323 0.26769645 ... 0.04424779 0.06259905 0.00569995]\n",
            " ...\n",
            " [0.08163835 0.32179418 0.05349678 ... 0.01902655 0.0570523  0.02040584]\n",
            " [0.06623226 0.44733297 0.11769291 ... 0.07876106 0.09429477 0.22993616]\n",
            " [0.08275541 0.50161638 0.12272373 ... 0.03451327 0.09033281 0.24635203]]\n",
            "['vrl' 'vrl' 'vrl' ... 'pri' 'pri' 'pri']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "np.random.seed(42)\n",
        "\n",
        "data = pd.read_csv('./codon_usage.csv')\n",
        "data = data.drop(data.columns[[1,2,3,4]], axis=1)\n",
        "data = data.to_numpy()\n",
        "data = np.delete(data,[486,5063],0)\n",
        "target = data[:,0]\n",
        "data = np.delete(data,0,1)\n",
        "data = data.astype(float)\n",
        "sss = StratifiedShuffleSplit(n_splits=1,train_size=0.2, random_state=42)\n",
        "D = 0\n",
        "T = 0\n",
        "for ind, _ in sss.split(data,target):\n",
        "  ind = np.sort(ind)\n",
        "  D = data[ind]\n",
        "  T = target[ind]\n",
        "scaler = MinMaxScaler(copy=False)\n",
        "scaler.fit_transform(D)\n",
        "\n",
        "print(D)\n",
        "print(T)\n",
        "\n",
        "a=_, b = np.unique(T, return_index = True)\n",
        "target_dict = dict.fromkeys(T[np.sort(b)], 0)\n",
        "for i in T:\n",
        "  target_dict[i]+=1\n",
        "true_sizes = []\n",
        "\n",
        "for i in target_dict.keys():\n",
        "  true_sizes.append(target_dict[i])\n",
        "target_ind = [0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "j=0\n",
        "for i in target_dict.keys():\n",
        "  if j!=0:\n",
        "    target_ind[j]+=target_dict[i] + target_ind[j-1]\n",
        "  else:\n",
        "    target_ind[j] = target_dict[i]\n",
        "  j+=1\n",
        "\n",
        "\n",
        "def HT(target_dict, D):\n",
        "  ht = 0\n",
        "  for i in target_dict.keys():\n",
        "    ht += (target_dict[i]/D.shape[0])*np.log(target_dict[i]/D.shape[0])\n",
        "  ht = -ht\n",
        "  return ht\n",
        "\n",
        "def pij(k_pred, k, target_ind, cluster_index, n):\n",
        "  pijs = np.zeros((k_pred,k))\n",
        "  for c in range(k_pred):\n",
        "    beg = 0\n",
        "    end = 0\n",
        "    for d in range(k):\n",
        "      count = 0\n",
        "      if d!=0:\n",
        "        beg = target_ind[d-1]\n",
        "      else:\n",
        "        beg = 0\n",
        "      end = target_ind[d]\n",
        "      for ind in range(len(cluster_index[c])):\n",
        "        if (cluster_index[c][ind] >= beg and cluster_index[c][ind] <end):\n",
        "          count+=1\n",
        "      pijs[c][d] = count/n\n",
        "  hct = 0\n",
        "  for i in range(k_pred):\n",
        "    for j in range(k):\n",
        "      hct += pijs[i][j] * np.log(pijs[i][j] + (.0000000000001))\n",
        "  hct = -hct\n",
        "  return hct\n",
        "\n",
        "\n",
        "def HC(final_clusters, k, n):\n",
        "  hc = 0\n",
        "  for h in range(k):\n",
        "    p = len(final_clusters[h])/n\n",
        "    if p!=0:\n",
        "      hc += p * np.log(p)\n",
        "      # if p==1:\n",
        "      #   hc += -1\n",
        "  hc = -hc\n",
        "  return hc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DENCLUE Algorithm"
      ],
      "metadata": {
        "id": "Xel0p2LvqFpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.resample import h\n",
        "from pandas.core.arrays.numeric import numbers\n",
        "import math\n",
        "\n",
        "def gaussian(x,D,h,d):\n",
        "  a = x - D\n",
        "  b = -(np.linalg.norm(a,axis=1)**2)/(2*(h**2))\n",
        "  t2 = np.exp(b)\n",
        "  gauss = t2/((math.sqrt(2*math.pi))**d)\n",
        "  return gauss\n",
        "\n",
        "def findattractor(x, D, h, e, numPoints, numDims):\n",
        "  while(True):\n",
        "    x_prev = np.copy(x)\n",
        "\n",
        "    g = gaussian(x,D,h,numDims)\n",
        "    g = g.reshape((-1,1))\n",
        "    denom = np.sum(g)\n",
        "    num = np.sum(np.multiply(g,D),axis=0)\n",
        "\n",
        "    x = num/denom #(mean shift)\n",
        "\n",
        "    if (np.linalg.norm(x-x_prev)<=e):\n",
        "      break\n",
        "  return x\n",
        "\n",
        "def densityEstimation(x, D, h, numPoints, numDims):\n",
        "  g = gaussian(x,D,h,numDims)\n",
        "  fx = np.sum(g)/(numPoints*(h**numDims))\n",
        "  return fx\n",
        "\n",
        "def denclue(D,h,ee,e):\n",
        "  numPoints = D.shape[0]\n",
        "  numDims = D.shape[1]\n",
        "  Attractors=[]\n",
        "  count=0\n",
        "  for i in range(numPoints):\n",
        "    xStar = findattractor(D[i],D,h,e, numPoints, numDims)\n",
        "    if densityEstimation(xStar, D, h, numPoints, numDims)>=ee:\n",
        "      Attractors.append(xStar)\n",
        "      count+=1\n",
        "  C = list(range(D.shape[0]))\n",
        "  for att in range(len(Attractors)):\n",
        "    for att2 in range(att+1, len(Attractors)):\n",
        "      if C[att] == C[att2]:\n",
        "        continue\n",
        "      if (np.linalg.norm(Attractors[att]-Attractors[att2])**2 < .0002):\n",
        "        C[att2] = C[att]\n",
        "\n",
        "  R = dict()\n",
        "  for clust in range(len(C)):\n",
        "    if C[clust] not in R.keys():\n",
        "      R[C[clust]] = [clust]\n",
        "    else:\n",
        "      R[C[clust]].append(clust)\n",
        "\n",
        "  clusters = []\n",
        "  print(\"Number of Clusters: \")\n",
        "  print(len(R))\n",
        "  print(\"Size of Each Cluster\")\n",
        "  for i in R.keys():\n",
        "    print(len(R[i]))\n",
        "    clusters.append(R[i])\n",
        "  return clusters\n",
        "\n",
        "\n",
        "clusters = denclue(D,0.5,10**-7,0.1)\n",
        "\n",
        "# NMI\n",
        "hc = HC(clusters,len(clusters),D.shape[0])\n",
        "\n",
        "ht = HT(target_dict, D)\n",
        "\n",
        "hct = pij(len(clusters),11,target_ind,clusters, D.shape[0])\n",
        "\n",
        "ict = hc + ht - hct\n",
        "\n",
        "nmi = ict/math.sqrt(hc*ht)\n",
        "\n",
        "print(\"NMI\")\n",
        "print(nmi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wamX-F7CqHdP",
        "outputId": "a9753de7-0b21-4be7-aaaa-fb714fb62a1f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Clusters: \n",
            "10\n",
            "Size of Each Cluster\n",
            "107\n",
            "1\n",
            "5\n",
            "20\n",
            "131\n",
            "1\n",
            "1\n",
            "2333\n",
            "1\n",
            "5\n",
            "NMI\n",
            "0.19846115830680033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Markov Clustering"
      ],
      "metadata": {
        "id": "E1qUt5vFofAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Algorithm"
      ],
      "metadata": {
        "id": "tyTbsfFsu0Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# print(D)\n",
        "R = np.zeros((D.shape[0],1))\n",
        "for i in range(D.shape[0]):\n",
        "  R[i] = np.square(D[i]).sum()\n",
        "A = np.exp((2*np.transpose(np.matmul(D,np.transpose(D)))-R-np.transpose(R))/(2*(.5**2)))\n",
        "# print(A)\n",
        "\n",
        "# A = np.array([[1, 1, 0, 1, 0, 1, 0],[1, 1, 1, 1, 0, 0, 0],[0, 1, 1, 1, 0, 0, 1],[1, 1, 1, 1, 1, 0, 0],[0, 0, 0, 1, 1, 1, 1],[1, 0, 0, 0, 1, 1, 1],[0, 0, 1, 0, 1, 1, 1]])\n",
        "\n",
        "\n",
        "def MarkovClustering(A,r,e):\n",
        "  # calculate Mt\n",
        "  i=0\n",
        "  j=0\n",
        "  An = A.shape[0]\n",
        "  Mt = np.zeros((An,An))\n",
        "  for i in range(A.shape[0]):\n",
        "    Mt[i] = A[i]/np.sum(A[i])\n",
        "  t=0\n",
        "  while (True):\n",
        "    t+=1\n",
        "    M_prev = np.copy(Mt)\n",
        "    Mt = np.dot(M_prev,M_prev)\n",
        "    Mt_new = Mt**r\n",
        "\n",
        "    for i in range(Mt.shape[0]):\n",
        "      Mt_new[i] = Mt_new[i]/np.sum(Mt_new[i])\n",
        "    Mt = Mt_new\n",
        "    # Mt = np.around(Mt,40)\n",
        "\n",
        "    if np.linalg.norm(Mt-M_prev)<=e:\n",
        "      break\n",
        "  # print(t)\n",
        "  return Mt\n",
        "\n",
        "\n",
        "r = 2.8\n",
        "while (r<2.9):\n",
        "\n",
        "  print(\"R: \" + str(r))\n",
        "\n",
        "  M_final = MarkovClustering(A,r,0.001)\n",
        "  # print(M_final)\n",
        "\n",
        "\n",
        "  clustered_nodes = set()\n",
        "  Adj = list()\n",
        "  for i in range(M_final.shape[0]):\n",
        "    Adj.append([])\n",
        "  for i in range(M_final.shape[0]):\n",
        "    for j in range(M_final.shape[1]):\n",
        "      if M_final[i][j]>0:\n",
        "        Adj[j].append(i)\n",
        "        clustered_nodes.add(i)\n",
        "\n",
        "  print(\"Size of clusters: \")\n",
        "  count=0\n",
        "  clusters = []\n",
        "  cluster_sizes = []\n",
        "  for c in Adj:\n",
        "    if len(c)>0:\n",
        "      cluster_sizes.append(len(c))\n",
        "      clusters.append(c)\n",
        "      count+=1\n",
        "  print(cluster_sizes)\n",
        "  print(\"Number of Clusters\")\n",
        "  print(count)\n",
        "\n",
        "  hc = HC(clusters,len(clusters),A.shape[0])\n",
        "\n",
        "\n",
        "  hct = pij(len(clusters), 11 ,target_ind,clusters, A.shape[0])\n",
        "\n",
        "\n",
        "  ict = hc + ht - hct\n",
        "\n",
        "  nmi = ict/math.sqrt(hc*ht)\n",
        "\n",
        "  print(\"NMI:\")\n",
        "\n",
        "  print(nmi)\n",
        "  r+=.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5zAMMG-u1vL",
        "outputId": "3eae4ddd-d9fc-493c-9b4e-437c6b37da0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R: 2.8\n",
            "Size of clusters: \n",
            "[1, 1, 1, 1, 2, 280, 1, 278, 1, 2, 1, 1, 1, 1789, 1, 2, 1, 1, 1, 1, 1, 36, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 464, 5, 1, 1]\n",
            "Number of Clusters\n",
            "38\n",
            "NMI:\n",
            "0.23694101527386047\n"
          ]
        }
      ]
    }
  ]
}